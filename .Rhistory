index=['a', 'b', 'c', 'd'])
data['b']
# create a dataframe from dictionary (see Basic Knowledge file for dictionaries)
data = pd.DataFrame(
{
"Name": [
"Braund, Mr. Owen Harris",
"Allen, Mr. William Henry",
"Bonnell, Miss. Elizabeth",
np.NaN
],
"Age": [22, 35, 58,np.NaN],
"Sex": ["male", "male", "female", np.NaN],
}
)
data
# alternative from list of tuples
names = [
("M. Rossi", 22, "male"),
("Mme Bianchi", 21, "female")
]
pd.DataFrame(names, columns=("Name", "Age", "Gender"))
# from numpy arrays
names = ["M. Rossi","Mme Bianchi"]
age = [22,21]
sex = ["male","female"]
pd.DataFrame(np.array([names,age,sex]).T, columns=("Names","Age","Gender"))
# get info about data variables
data.info()
data.head()
data.shape
data.describe()
data.columns
# NaNs in the whole database
# The any() function returns True if any item in an iterable are true, otherwise it returns False.
data.isnull().values.any()
# Check NaNs among columns
# sum among all columns
data.isnull().sum()
# count number of nas in each row
for i in range(len(data.index)) :
print(" Total NaN in row", i + 1, ":",
data.iloc[i].isnull().sum())
# subsetting columns by their name
data["Name"]
data.iloc[:,[0,2]]
# select row
data.iloc[0,:]
type(data.iloc[0,:])
type(data.iloc[:,0])
# specific rows
data[data["Age"] <30]
# specific rows + cols
## notice : loc diff from iloc
data.loc[data["Age"]<30, ["Name","Age"]]
data = pd.Series([0.25, 0.5, 0.75, 1.0],
index=[2, 5, 3, 7])
data
data = pd.Series([0.25, 0.5, 0.75, 1.0],
index=[2, 5, 3, 7])
data
data[7]
data
index
pd.Series(data, index=[1,2,3,4])
data
pd.Series(data, index=[1,2,3,4])
pd.Series(data, index=[0,2,3,4])
data
data
pd.Series(np.random(4), index=[1,2,3,4])
np.random(4)
help(np.random)
np.rand(4)
np.random.rand(4)
pd.Series(np.random.rand(4), index=[1,2,3,4])
pd.Series('Baseball':'NY Yankees', 'Football':'Juventus', 'Tennis':'Nadal')
pd.Series({'Baseball':'NY Yankees', 'Football':'Juventus', 'Tennis':'Nadal'})
pd.Series({'Baseball':'NY Yankees', 'Football':'Juventus', 'Tennis':'Nadal'}, index = [3,2,1])
pd.Series({'Baseball':'NY Yankees', 'Football':'Juventus', 'Tennis':'Nadal'}, index = ['Baseball','Football'])
population_dict = {'California': 38332521,
'Texas': 26448193,
'New York': 19651127,
'Florida': 19552860,
'Illinois': 12882135}
population = pd.Series(population_dict)
population
population['California']
pd.DataFrame(population)
pd.DataFrame(population, columns=['population'])
areas_dict = {'California': 35678,
'Texas': 457886,
'New York': 45789,
'Florida': 345688,
'Illinois': 34678}
areas = pd.Series(areas_dict)
areas
pd.DataFrame(population, areas)
pd.DataFrame([population, areas])
pd.DataFrame(values=population, areas, columns=['population', 'area'])
pd.DataFrame(values=[population, areas], columns=['population', 'area'])
pd.DataFrame({'population'=population, 'areas'=areas)
pd.DataFrame({'population'=population, 'areas'=areas})
pd.DataFrame({'population':population, 'areas':areas})
pd.DataFrame({'population':population, 'areas':areas}, columns=['suca','su'])
pd.DataFrame({'population':population, 'areas':areas})
pd.DataFrame({'Pop':population, 'Area':areas})
areas_dict = {'California': 35678,
'New York': 45789,
'Florida': 345688,
'Texas': 457886,
'Illinois': 34678}
areas = pd.Series(areas_dict)
pd.DataFrame({'Pop':population, 'Area':areas})
pd.DataFrame(population, columns=['population'])
pd.DataFrame(population, columns=['suca'])
pd.DataFrame(population, columns=['Pop'])
pd.DataFrame([population, areas])
pd.DataFrame([population, areas].t)
scua=[population, areas]
scua.t
scua.t()
scua.T
scua.T()
pd.DataFrame(np.array([population, areas])
pd.DataFrame(np.array([population, areas]))
pd.DataFrame(np.array([population, areas]))
pd.DataFrame(np.array([population, areas]).T)
pd.DataFrame(np.array([population, areas]).T, columns=['Pop','Area'])
pd.DataFrame(np.array([population, areas]).T, columns=['Pop','Area'], index=[population.index])
data.index
data.info()
data = pd.DataFrame(
{
"Name": [
"Braund, Mr. Owen Harris",
"Allen, Mr. William Henry",
"Bonnell, Miss. Elizabeth",
np.NaN
],
"Age": [22, 35, 58,np.NaN],
"Sex": ["male", "male", "female", np.NaN],
}
)
data
data.info()
data.head()
data.shape
data.describe()
data.columns
data.index
# from a series
pd.DataFrame(population, columns=['Pop'])
# from 2 series (several ways)
areas_dict = {'California': 35678,
'New York': 45789,
'Florida': 345688,
'Texas': 457886,
'Illinois': 34678}
areas = pd.Series(areas_dict)
pd.DataFrame({'Pop':population, 'Area':areas})
pd.DataFrame(np.array([population, areas]).T, columns=['Pop','Area'], index=[population.index])
# create a dataframe from dictionary (more complicated)
data = pd.DataFrame(
{
"Name": [
"Braund, Mr. Owen Harris",
"Allen, Mr. William Henry",
"Bonnell, Miss. Elizabeth",
np.NaN
],
"Age": [22, 35, 58,np.NaN],
"Sex": ["male", "male", "female", np.NaN],
}
)
data
# alternative from list of tuples
names = [
("M. Rossi", 22, "male"),
("Mme Bianchi", 21, "female")
]
pd.DataFrame(names, columns=("Name", "Age", "Gender"))
# from numpy arrays
names = ["M. Rossi","Mme Bianchi"]
age = [22,21]
sex = ["male","female"]
pd.DataFrame(np.array([names,age,sex]).T, columns=("Names","Age","Gender"))
# get info about data variables
data.info()
data.head()
data.shape
data.describe()
data.columns
data.index
# NaNs in the whole database
# The any() function returns True if any item in an iterable are true, otherwise it returns False.
data.isnull().values.any()
# Check NaNs among columns
# sum among all columns
data.isnull().sum()
# count number of nas in each row
for i in range(len(data.index)) :
print(" Total NaN in row", i + 1, ":",
data.iloc[i].isnull().sum())
# specific rows
data[data["Age"] <30]
# specific rows + cols
## notice : loc diff from iloc
data.loc[data["Age"]<30, ["Name","Age"]]
data[data["Age"] <30]
# specific rows + cols
## notice : loc diff from iloc
data.loc[data["Age"]<30, ["Name","Age"]]
data
type(data)
data[1,3]
data.shape
data
data.shape
data[1]
data[1,3]
series = pd.Series([0.25, 0.5, 0.75, 1.0],
index=['a', 'b', 'c', 'd'])
dataframe = pd.DataFrame({
"Name": [
"Braund, Mr. Owen Harris",
"Allen, Mr. William Henry",
"Bonnell, Miss. Elizabeth",
np.NaN
],
"Age": [22, 35, 58,np.NaN],
"Sex": ["male", "male", "female", np.NaN],
})
dataframe
data["Name"]
series[1]
series['a']
series[series>0.5]
data["Name":"Age"]
data.Name
data["Name":"Age"]
series.iloc(1)
series.loc[1]
series.loc
series
series
series.loc['a]
data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])
data
data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])
data
# explicit index when indexing
data[1]
# implicit index when slicing
data[1:3]
data[1]
data[1]
data[1:3]
series
series.loc['a']
series.iloc[1]
series.iloc[0]
dataframe.loc['Name']
dataframe
dataframe.loc[1]
dataframe
dataframe.iloc[1]
dataframe.loc[1]
dataframe.loc[0]
}, index= ['a','b','c','d'])
dataframe = pd.DataFrame({
"Name": [
"Braund, Mr. Owen Harris",
"Allen, Mr. William Henry",
"Bonnell, Miss. Elizabeth",
np.NaN
],
"Age": [22, 35, 58,np.NaN],
"Sex": ["male", "male", "female", np.NaN],
}, index= ['a','b','c','d'])
dataframe
dataframe.loc['a']
dataframe.iloc[1]
dataframe.iloc[0]
dataframe.loc['a']
dataframe.iloc[1]
series.loc['a']
series.iloc[0]
dataframe.loc['a']
dataframe.iloc[0]
dataframe.iloc[:,[0,2]]
type(data.iloc[0,:])
dataframe.loc[data["Age"]<30, ["Name","Age"]]
dataframe.loc[dataframe["Age"]<30, ["Name","Age"]]
dataframe.loc[dataframe["Age"]<30, ["Name","Age"]]
dataframe.iloc[:,[0,2]]
dataframe.loc[:, ["Name","Age"]]
dataframe.iloc[:,[0,2]]
dataframe.loc[:, ["Name","Age"]]
dataframe.iloc[:,[0,2]]
dataframe
dataframe.loc[:, ["Name","Sex"]]
dataframe.iloc[:,[0,2]]
dataframe.loc[:, ["Name","Sex"]]
data
data.isnull()
data[data.notnull()]
# function isnull
data.isnull()
data[data.notnull()]
# using indexing on condition
data[data.notnull()]
data.dropna()
data
data = pd.DataFrame(
{
"Name": [
"Braund, Mr. Owen Harris",
"Allen, Mr. William Henry",
"Bonnell, Miss. Elizabeth",
np.NaN
],
"Age": [22, 35, 58,np.NaN],
"Sex": ["male", "male", "female", np.NaN],
}
)
data
data.isnull()
data[data.notnull()]
# count number of nas in each row
for i in range(len(data.index)) :
print(" Total NaN in row", i + 1, ":",
data.iloc[i].isnull().sum())
for i in range(len(data.index)) :
print(" Total NaN in row", i + 1, ":",
data.iloc[i].isnull().sum())
for i in range(len(data.index)) :
print(" Total NaN in row", i + 1, ":",
data.iloc[i].isnull().sum())
pass
for i in range(len(data.index)) :
print(" Total NaN in row", i + 1, ":",
data.iloc[i].isnull().sum())
pass
data.isnull().sum()
x = make_df('AB', [0, 1])
y = make_df('AB', [2, 3])
y.index = x.index  # make duplicate indices!
display('x', 'y', 'pd.concat([x, y])')
def make_df(cols, ind):
"""Quickly make a DataFrame"""
data = {c: [str(c) + str(i) for i in ind]
for c in cols}
return pd.DataFrame(data, ind)
df1 = make_df('AB', [1, 2])
df2 = make_df('AB', [3, 4])
display('df1', 'df2', 'pd.concat([df1, df2])')
class display(object):
"""Display HTML representation of multiple objects"""
template = """<div style="float: left; padding: 10px;">
<p style='font-family:"Courier New", Courier, monospace'>{0}</p>{1}
</div>"""
def __init__(self, *args):
self.args = args
def _repr_html_(self):
return '\n'.join(self.template.format(a, eval(a)._repr_html_())
for a in self.args)
def __repr__(self):
return '\n\n'.join(a + '\n' + repr(eval(a))
for a in self.args)
display('df1', 'df2', 'pd.concat([df1, df2])')
print('df1', 'df2', 'pd.concat([df1, df2])')
print(df1, df2, pd.concat([df1, df2]))
pd.concat([df1, df2])
df2
df1
df1 = make_df('AB', [1, 2])
df2 = make_df('AB', [3, 4])
print(df1, df2, pd.concat([df1, df2]))
pd.concat([df1, df2])
df1
df2
pd.concat([df1, df2])
pd.concat([df3, df4], axis='col')
df3 = make_df('AB', [0, 1])
df4 = make_df('CD', [0, 1])
df3
df4
pd.concat([df3, df4], axis='col')
pd.concat([df3, df4], axis=1)
pd.concat([df3, df4], axis=1) # axis = 1 columns, axis = 0 rows
pd.concat([df1, df2])
print(pd.concat([x, y]))
x = make_df('AB', [0, 1])
y = make_df('AB', [2, 3])
y.index = x.index  # make duplicate indices!
print(pd.concat([x, y]))
df5 = make_df('ABC', [1, 2])
df6 = make_df('BCD', [3, 4])
df5
df6
pd.concat([df5, df6])
pd.concat([df5, df6], join='inner')
pd.concat([df5, df6], join='outer')
pd.concat([df5, df6], join_axes=df5.columns)
pd.concat([df5, df6], join_axes='df5.columns')
pd.concat([df5, df6], join_axes=[df5.columns])
help(pd.concat())
help(pd.concat
)
help(pd.concat)
pd.concat([df5, df6], axes=[df5.columns])
pd.concat([df5, df6], join_axes=[df5.columns])
pd.concat([df5, df6]).reindex(df5.columns)
pd.concat([df5, df6], axis=1).reindex(df5.columns)
pd.concat([df5, df6], join=[df5.columns])
pd.concat([df5, df6], key=[df5.columns])
pd.concat([df5, df6]).reindex(df5.columns)
pd.concat([df5, df6])
pd.concat([df5, df6], axis=1).reindex(df5.columns)
pd.concat([df5, df6], axis=1).reindex([df5.columns])
pd.concat([df5, df6.reindex(df5.columns)])
pd.concat([df5, df6.reindex(columns=df5.columns)])
df5
df6
df6.reindex
df6.reindex(columns=df5.columns)
df5
df5
df6
df5
df6
pd.concat([df5, df6.reindex(columns=df5.columns)])
df5
df6
df6.reindex(columns=df5.columns)
pd.concat([df5, df6.reindex(columns=df5.columns)])
df1.append(df2)
x = make_df('AB', [0, 1])
y = make_df('AB', [2, 3])
print(pd.concat([x, y]))
x = make_df('AB', [0, 1])
y = make_df('AB', [2, 3])
print(pd.concat([x, y]))
x = make_df('AB', [0, 1])
y = make_df('AB', [2, 3])
x
y
print(pd.concat([x, y]))
x = make_df('AB', [0, 1])
y = make_df('AC', [2, 3])
x
y
print(pd.concat([x, y]))
x = make_df('AB', [0, 1])
y = make_df('AC', [2, 3])
x
y
print(pd.concat([x, y]))
x = make_df('AB', [0, 1])
y = make_df('AC', [2, 3])
x
y
print(pd.concat([x, y]))
x = make_df('AB', [0, 1])
y = make_df('AC', [4, 3])
x
y
print(pd.concat([x, y]))
df3 = pd.merge(df1, df2)
df3
df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],
'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})
'hire_date': [2004, 2008, 2012, 2014]})
df3 = pd.merge(df1, df2)
df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],
'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})
df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],
'hire_date': [2004, 2008, 2012, 2014]})
df3 = pd.merge(df1, df2)
df3
df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],
'supervisor': ['Carly', 'Guido', 'Steve']})
pd.merge(df3, df4)
df4
df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],
'supervisor': ['Carly', 'Guido', 'Steve']})
df3
df4
pd.merge(df3, df4)
pd.merge(df1, df5)
df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',
'Engineering', 'Engineering', 'HR', 'HR'],
'skills': ['math', 'spreadsheets', 'coding', 'linux',
'spreadsheets', 'organization']})
df5
pd.merge(df1, df5)
df1
df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',
'Engineering', 'Engineering', 'HR', 'HR'],
'skills': ['math', 'spreadsheets', 'coding', 'linux',
'spreadsheets', 'organization']})
df5
df1
pd.merge(df1, df5)
pd.merge(df1, df2, on='employee')
df1
df2
pd.merge(df1, df2, on='employee')
df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],
'salary': [70000, 80000, 120000, 90000]})
pd.merge(df1, df3, left_on="employee", right_on="name")
